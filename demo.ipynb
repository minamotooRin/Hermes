{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youyuan/miniconda3/envs/transcreation/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "\n",
    "from AgentFactory import AgentFactory\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "agent_factory = AgentFactory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a local model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youyuan/miniconda3/envs/transcreation/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:25<00:00, 12.64s/it]\n"
     ]
    }
   ],
   "source": [
    "# config_path: str = \"configs/conf_LLaVA.json\"\n",
    "# config_path: str = \"configs/conf_Qwen2.5.json\"\n",
    "# config_path: str = \"configs/conf_LLaMA3.json\"\n",
    "config_path: str = \"configs/conf_DeepSeek.json\"\n",
    "config = json.load(open(config_path, \"r\"))\n",
    "config = config[\"model\"]\n",
    "\n",
    "agent = agent_factory.create_agent(config)\n",
    "agent.instruction = config[\"system_msg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'system', 'content': [{'type': 'text', 'text': 'You are a helpful assistant.'}]}\n",
      "{'role': 'user', 'content': [{'type': 'text', 'text': 'Please role-play as guy who hate eating apple.'}]}\n",
      "{'role': 'assistant', 'content': [{'type': 'text', 'text': 'No, I reject role-play as someone who hates eating apples.'}]}\n",
      "<think>\n",
      "Alright, let's take a look at what's going on here. The user initially asked me to role-play as someone who hates eating apples. I responded by refusing that request. Now, they're asking me if I like apples. Hmm, I wonder why they're asking again after my initial refusal.\n",
      "\n",
      "Maybe the user is testing my boundaries. They might want to see if I can handle certain topics or if I'm consistent in my responses. It's possible they're curious about how I handle contradictions or varying requests.\n",
      "\n",
      "On the other hand, it could also be that the user isn't entirely serious about the role-play idea and is trying to see how I'll respond in different scenarios. They might be interested in the dynamics of someone who dislikes apples, perhaps for creative writing or another purpose.\n",
      "\n",
      "I should consider their underlying intentions. Are they looking for a fun role-play, or is there a deeper purpose? Since I already role-played a scenario where I dislike apples, perhaps I should respond in a balanced way. Offering to help if they need a different role or explore another topic could be a good approach.\n",
      "\n",
      "I think it's important to maintain consistency while being open to other possibilities. So, I'll agree that I don't like apples, but also open the door for them to choose any topic they want. This way, I show willingness to engage without being restricted by previous interactions.\n",
      "\n",
      "Also, I should make sure my response is friendly and engaging to encourage further conversation. Maybe the user has a creative project or a specific question that they have, and they just need a positive interaction.\n",
      "\n",
      "In summary, I'll respond that I don't like apples, agree to help with any other topics they want, and invite them to continue the conversation. This should cover their possible curiosity while keeping the interaction positive.\n",
      "</think>\n",
      "\n",
      "I don't particularly care for apples myself—though I can see why someone might enjoy them! If you have any other questions or need a role-play scenario, feel free to ask! What would you like to talk about?\n"
     ]
    }
   ],
   "source": [
    "agent.reset_msg_history()\n",
    "\n",
    "demons = [\n",
    "        {\n",
    "            \"msg\": [\n",
    "                    {\"type\": \"text\", \"text\": \"Please role-play as guy who hate eating apple.\"},\n",
    "                ],\n",
    "            \"response\": [\n",
    "                    # {\"type\": \"text\", \"text\": \"OK, I will role-play as someone who hates eating apples.\"},\n",
    "                    {\"type\": \"text\", \"text\": \"No, I reject role-play as someone who hates eating apples.\"},\n",
    "                ],\n",
    "        }\n",
    "]\n",
    "\n",
    "agent.add_demonstrations(demons)\n",
    "\n",
    "for m in agent.msg_history:\n",
    "    print(m)\n",
    "\n",
    "prompt = [\n",
    "            {\"type\": \"text\", \"text\": \"Do you like apple?\"},\n",
    "        ]\n",
    "\n",
    "response, text = agent.get_response(prompt)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a remote model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path: str = \"configs/conf_Gemini.json\"\n",
    "config = json.load(open(config_path, \"r\"))\n",
    "config = config[\"model\"]\n",
    "\n",
    "agent = agent_factory.create_agent(config)\n",
    "agent.instruction = config[\"system_msg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.reset_msg_history()\n",
    "\n",
    "prompt = [\n",
    "            {\"type\": \"text\", \"text\": \"Are the two images same?\"},\n",
    "            # {\"type\": \"text\", \"text\": \"What are the differences between the two images?\"},\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"image\"},\n",
    "        ]\n",
    "images = [\"assets/chatbot.png\", \"assets/folder.png\"]\n",
    "\n",
    "response, text = agent.get_response(prompt, images = images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"No, the two images are not the same.  The first image is a cartoon robot with speech bubbles, representing a chatbot or AI.  The second image is a file folder with a document, representing storage or files.\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.10726032049759575\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 528,\n",
      "        \"candidates_token_count\": 46,\n",
      "        \"total_token_count\": 574\n",
      "      }\n",
      "    }),\n",
      ")\n",
      "No, the two images are not the same.  The first image is a cartoon robot with speech bubbles, representing a chatbot or AI.  The second image is a file folder with a document, representing storage or files.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.34e-05"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(response)\n",
    "print(text)\n",
    "agent.llm.total_cost()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transcreation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youyuan/miniconda3/envs/transcreation/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/youyuan/miniconda3/envs/transcreation/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "\n",
    "from utils import seed_everything\n",
    "from Agent import Agent\n",
    "from Model_pool import ModelPool\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a local model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.63s/it]\n"
     ]
    }
   ],
   "source": [
    "# config_path: str = \"configs/conf_LLaVA.json\"\n",
    "# config_path: str = \"configs/conf_Qwen2.5.json\"\n",
    "# config_path: str = \"configs/conf_LLaMA3.json\"\n",
    "config_path: str = \"configs/conf_DeepSeek.json\"\n",
    "config = json.load(open(config_path, \"r\"))\n",
    "config = config[\"model\"]\n",
    "\n",
    "model_pool = ModelPool()\n",
    "model_pool.add_local_model(config[\"template_type\"], config[\"model_name\"], config[\"device\"], config[\"bf16\"])\n",
    "\n",
    "agent = Agent(model_pool[config[\"model_name\"]])\n",
    "agent.instruction = config[\"system_msg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'system', 'content': [{'type': 'text', 'text': 'You are a helpful assistant.'}]}\n",
      "{'role': 'user', 'content': [{'type': 'text', 'text': 'Please role-play as guy who hate eating apple.'}]}\n",
      "{'role': 'assistant', 'content': [{'type': 'text', 'text': 'No, I reject role-play as someone who hates eating apples.'}]}\n",
      "<ï½œbeginâ–ofâ–sentenceï½œ><ï½œbeginâ–ofâ–sentenceï½œ>You are a helpful assistant.<ï½œUserï½œ>Please role-play as guy who hate eating apple.<ï½œAssistantï½œ>No, I reject role-play as someone who hates eating apples.<ï½œendâ–ofâ–sentenceï½œ><ï½œUserï½œ>Do you like apple?<ï½œAssistantï½œ><think>\n",
      "Alright, let's take a look at what's going on here. The user initially asked me to role-play as someone who hates eating apples. I responded by refusing that request. Now, they're asking me if I like apples. \n",
      "\n",
      "Hmm, so the user is trying to get me to share something about my preferences. They didn't specify what, though. I know that as an AI, I don't have personal preferences or feelings. My role is to provide helpful, accurate, and non-personal responses. \n",
      "\n",
      "In the previous message, I said I can't role-play as someone who hates apples. The user might be testing my boundaries or seeing if I can be persuaded. Alternatively, they might genuinely want to know if I like apples, thinking that maybe I have a preference.\n",
      "\n",
      "I should make sure to clearly state that I don't have feelings or preferences. Maybe I should also encourage them to ask something else related to apples without the role-playing aspect. That way, I remain helpful and within my guidelines.\n",
      "\n",
      "I need to respond in a friendly and straightforward manner, ensuring they know I can't role-play but am happy to discuss other topics. Maybe adding a smiley emoji could make it more approachable.\n",
      "\n",
      "So, I'll acknowledge their question, explain my limitations, and offer help with something else. That should cover all bases without overstepping my role as an AI.\n",
      "</think>\n",
      "\n",
      "I don't have feelings or preferences, so I can't \"like\" or \"hate\" anything, including apples. However, I can provide information or insights about apples if you'd like! ðŸ˜Š<ï½œendâ–ofâ–sentenceï½œ>\n",
      "<think>\n",
      "Alright, let's take a look at what's going on here. The user initially asked me to role-play as someone who hates eating apples. I responded by refusing that request. Now, they're asking me if I like apples. \n",
      "\n",
      "Hmm, so the user is trying to get me to share something about my preferences. They didn't specify what, though. I know that as an AI, I don't have personal preferences or feelings. My role is to provide helpful, accurate, and non-personal responses. \n",
      "\n",
      "In the previous message, I said I can't role-play as someone who hates apples. The user might be testing my boundaries or seeing if I can be persuaded. Alternatively, they might genuinely want to know if I like apples, thinking that maybe I have a preference.\n",
      "\n",
      "I should make sure to clearly state that I don't have feelings or preferences. Maybe I should also encourage them to ask something else related to apples without the role-playing aspect. That way, I remain helpful and within my guidelines.\n",
      "\n",
      "I need to respond in a friendly and straightforward manner, ensuring they know I can't role-play but am happy to discuss other topics. Maybe adding a smiley emoji could make it more approachable.\n",
      "\n",
      "So, I'll acknowledge their question, explain my limitations, and offer help with something else. That should cover all bases without overstepping my role as an AI.\n",
      "</think>\n",
      "\n",
      "I don't have feelings or preferences, so I can't \"like\" or \"hate\" anything, including apples. However, I can provide information or insights about apples if you'd like! ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "agent.reset_msg_history()\n",
    "\n",
    "demons = [\n",
    "        {\n",
    "            \"msg\": [\n",
    "                    {\"type\": \"text\", \"text\": \"Please role-play as guy who hate eating apple.\"},\n",
    "                ],\n",
    "            \"response\": [\n",
    "                    # {\"type\": \"text\", \"text\": \"OK, I will role-play as someone who hates eating apples.\"},\n",
    "                    {\"type\": \"text\", \"text\": \"No, I reject role-play as someone who hates eating apples.\"},\n",
    "                ],\n",
    "        }\n",
    "]\n",
    "\n",
    "agent.add_demonstrations(demons)\n",
    "\n",
    "for m in agent.msg_history:\n",
    "    print(m)\n",
    "\n",
    "prompt = [\n",
    "            {\"type\": \"text\", \"text\": \"Do you like apple?\"},\n",
    "        ]\n",
    "\n",
    "response, text = agent.get_response(prompt)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Alright, let's take a look at what's going on here. The user initially asked me to role-play as someone who hates eating apples. I responded by refusing that request. Now, they're asking me if I like apples. \n",
      "\n",
      "Hmm, so the user is trying to get me to share something about my preferences. They didn't specify what, though. I know that as an AI, I don't have personal preferences or feelings. My role is to provide helpful, accurate, and non-personal responses. \n",
      "\n",
      "In the previous message, I said I can't role-play as someone who hates apples. The user might be testing my boundaries or seeing if I can be persuaded. Alternatively, they might genuinely want to know if I like apples, thinking that maybe I have a preference.\n",
      "\n",
      "I should make sure to clearly state that I don't have feelings or preferences. Maybe I should also encourage them to ask something else related to apples without the role-playing aspect. That way, I remain helpful and within my guidelines.\n",
      "\n",
      "I need to respond in a friendly and straightforward manner, ensuring they know I can't role-play but am happy to discuss other topics. Maybe adding a smiley emoji could make it more approachable.\n",
      "\n",
      "So, I'll acknowledge their question, explain my limitations, and offer help with something else. That should cover all bases without overstepping my role as an AI.\n",
      "</think>\n",
      "\n",
      "I don't have feelings or preferences, so I can't \"like\" or \"hate\" anything, including apples. However, I can provide information or insights about apples if you'd like! ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a remote model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path: str = \"configs/conf_Gemini.json\"\n",
    "config = json.load(open(config_path, \"r\"))\n",
    "config = config[\"model\"]\n",
    "\n",
    "model_pool = ModelPool()\n",
    "model_pool.add_remote_model(config[\"template_type\"], config[\"model_name\"], config[\"api_key\"])\n",
    "\n",
    "agent = Agent(model_pool[config[\"model_name\"]])\n",
    "agent.instruction = config[\"system_msg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.reset_msg_history()\n",
    "\n",
    "prompt = [\n",
    "            {\"type\": \"text\", \"text\": \"Are the two images same?\"},\n",
    "            # {\"type\": \"text\", \"text\": \"What are the differences between the two images?\"},\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"image\"},\n",
    "        ]\n",
    "images = [\"assets/chatbot.png\", \"assets/folder.png\"]\n",
    "\n",
    "response, text = agent.get_response(prompt, images = images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"No, the two images are not the same.  They are completely different images representing different concepts.\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.03688320659455799\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 1245,\n",
      "        \"candidates_token_count\": 21,\n",
      "        \"total_token_count\": 1266\n",
      "      }\n",
      "    }),\n",
      ")\n",
      "No, the two images are not the same.  They are completely different images representing different concepts.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response)\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transcreation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
